\documentclass[article]{xmosmodern}

%\begin{document}
\start

\title{XS1 programming tips and tricks}
\version{0.6}
\yearmonthday{2010}{09}{30}
%\author{XMOS}

\maketitle

\section{Introduction}

This document presents a number of programming techniques for the XMOS
XCore XS1 architecture. Some of these methods put instructions specific to
the XCore XS1 (eg CRC, LMUL) to, possibly, unexpected uses.

\section{Realigning a data stream}

In some applications one would like to write a stream of data into memory, but the
destination location is not word aligned in memory. For example, a program
may be reading words from a
32-bit buffered port, and attempting to store these words in a packet
buffer that starts at address 0x13001.

\subsection{Using MACCU instructions}

Rather than resorting to short or byte stores, the MACCU instruction can be
used to realign the data in a single clock cycle. The MACCU instruction
computes:
\begin{eqnarray}
h:l &\leftarrow& h:l + x \times y
\end{eqnarray}
In other words:
\begin{eqnarray}
h &\leftarrow& h + (l + x \times y) \div 2^{32}\\
l &\leftarrow& (l + x \times y) \bmod 2^{32} 
\end{eqnarray}
We will use $y$ as a constant that denotes over how many bytes the data
should be realigned. Assuming that we want to shift by $n$ bytes, where $n$
is 0, 1, 2, or 3, we set $y$ to 0x1, 0x100, 0x10000, or 0x1000000.
$x$ is the word that is input, which contains the most
recently received byte (that should go at the highest location in memory)
in it most significant location, and the oldest data in its least significant
location.

Multiplying $x$ by $y$ into a 64 bit value will split the word into two
words: the least significant 32 bits of the answer contain the the $4-n$
oldest bytes of data: all 4 bytes for $n$ equals 0, 3 bytes for $n$ equals
1, and so on. The highest 32 bits of the answer contain the $n$ more recent
bytes. The trick is to keep those bytes for the next store, and add those in
with the $4-n$ bytes of the next iteration. Conveniently, the MACCU
instruction performs that addition.

In other words, we perform the following operations in a loop:
\begin{eqnarray}
x &\leftarrow& input\\
h &\leftarrow& 0\\
l &\leftarrow& l + (x \times y) \bmod 2^{32} \\
h &\leftarrow& h + (x \times y) \div 2^{32}\\
mem[] &\leftarrow& l\\
l &\leftarrow& h
\end{eqnarray}
The last operation can be removed by unrolling the loop once and renaming
the registers. An XC program that reads words from an input channel/port
and outputs realigned words to an output channel/port is shown below:
\begin{lstlisting}
unsigned y = 0x100;
unsigned h, l = 0, x;
while(...) {
    h = 0;
    i :> x;
    {h,l} = macu(h,l,x,y);
    o <: l;
    l = 0;
    i :> x;
    {l,h} = macu(l,h,x,y);
    o <: h;
}
\end{lstlisting}
Which realigns a byte stream by one byte. The variable $y$ can be set to
any other value with a single '1' bit to achieve different realignments.

Conversely, a MACCU instruction can also be used to pack 24 bit values into 32 bit
values - four MACCU instructions with values 1, 0x1000000, 0x1000, and 0x100
in succession will pack 4 24-bit values into 3 32-bit values.

\subsection{Realignment using a channel}

A channel can also be used to realign data. Data can be output to a channel
in words, and input in words. If, on purpose, a single token is output
prior to a series of word outputs, then each input will input one token
from the last word, and three tokens from the current word.

Since words are transmitted most significant byte first, the byte-reverse
function should be called prior to outputting a word, and after inputting
the word. As an example, the following two functions will realign the data
by one byte.

\begin{lstlisting}
#include <xclib.h>

void sender(streaming chanend x, int a[100]) {
    char c = 0;
    x <: c;
    for(int i = 0; i < 100; i++) {
        x <: byterev(a[i]);
    }
}

void receiver(streaming chanend x, int a[100]) {
    for(int i = 0; i < 100; i++) {
        x :> byterev(a[i]);
    }
    x :> char _;
}
\end{lstlisting}

This method is particularly useful on the edge of two processes, where
data would be communicated to another thread anyway. For example, a data
packet may have been received over ethernet and is transmitted to a second
thread for processing.

\section{Hash tables}
\label{section:hash}

A hash table is a well understood data structure to store data. Typically,
a hash table stores pairs {\em (key,value)}, and the objective is to use little
memory to store those but with a fast access mechanism. Hash tables are
described in detail by Knuth~\cite{knuth3}.

A good hash function is critical to making efficient hash tables. Good hash
functions can be expensive to compute, but functions that are cheap to
compute may have poor hashing qualities.

The XS1 instruction set offers a CRC instruction that can compute a reasonable
hash in a single clock cycle. The CRC instruction computes the modulo when
dividing by a binary polynomial. This is known to have good hashing
properties if the right polynomial is chosen.

The way to use the CRC instruction is as follows (assuming that there is an
array of words x[] over which we want to create a hash):
\begin{lstlisting}
  hash = ~0;
  for(int i = 0; i < n; i++) {
    crc32(hash, x[i], polynomial);
  }
\end{lstlisting}
For the special case where the key is only one word, this for-loop reverts
to one thread cycle to initialise the variable \lstinline$hash$, and call
to crc32() which is also executed in a single thread cycle.

The polynomial should be chosen as follows:
\begin{itemize}
  \item The length of the polynomial determines the size of the hashtable
    addressed. For a polynomial of length $n$, the hash table will have
    $2^n$ entries. A polynomial of length $n$ will have $32-n$ zero bits as
    its most significant bits, then a $1$ bit, and then zero and 1 bits.
  \item The polynomial should have good spreading properties. We refer to
    Knuth for details~\cite{knuth3}. As a rule of thumb, primitive
    polynomials~\cite{wikipedia-primitive-polynomial} are good.
\end{itemize}
If all values that are to be stored are known at compile time, then the
polynomial can be chosen to minimise the hashtable by performing an
exhaustive search over all possible polynomials.

\section{Parsing bit streams}

Many I/O interfaces require a bit-stream to be parsed. A simple parser
maintains a state, and on every input a state transition is made.
\begin{lstlisting}
  while(...) {
    p :> x;
    state = newstate[state][x];
  }
\end{lstlisting}
This method works fine, under two assumptions:
\begin{enumerate}
  \item There is enough time to perform the table lookup.
  \item There is enough memory to store the table.
\end{enumerate}
The latter can be a problem if the table is not very dense. For example, if
\lstinline$p$ is an 8-bit port (or an 8-bit buffered 1-bit port), it will
result in values between 0 and 255, but only one or two of these values may
be legal in any one state. In this case, a large part of the table will be
empty, or filled with ``ERROR'' states.

There are two other methods to parse a bit stream that avoid the above two
problems; a faster method that encodes the state in the code space, and a
memory efficient method that uses a hash table.

\subsection{Encoding the state in code space}

In order to encode the state machine in the code space, a {\em label} is used to denote each state;
an input to obtain data, and a conditional (or computed) branch to perform
a state change. For example, the following code has four states, encoding
the last two bits of data that have been input on a one bit port:

\begin{lstlisting}
S00:
    in    r1, res[r0]
    bf    r1, S00
S01:
    in    r1, res[r0]
    bf    r1, S10
S11:
    in    r1, res[r0]
    bt    r1, S11
S10:
    in    r1, res[r0]
    bt    r1, S01
    bu    S00
\end{lstlisting}

The longest trail of instructions between two subsequent inputs is three,
hence this system can parse one bit every three thread cycles. Extra
instructions can be added to the code to do something useful on 
state transactions.

More bits can be parsed at any one time by using a buffered port, for example a
4-bit buffered port that will result in a 4-bit value, where a \lstinline$bru$
instruction can be used to jump based on that value, and \lstinline$bl$ instructions to
jump to a new state (note that a \lstinline$bl$ instruction can jump up to
1024 instructions either way). When values are input from a serialising
port, the least significant bit is the oldest bit, and the most significant
bit input is the most recent bit. Hence, if on a 4-bit port the value
\lstinline$0010$ (2) appears, then that means that the port clocked in a
'0', a '1', a '0', and a '0'. In the state machine we reflect this by
jumping to a state \lstinline$S0100$:

\begin{lstlisting}
S:
    IN       r1, r0
    BRU      r1
    BLRF_u10 S0000
    BLRF_u10 S1000 // Input was '1' followed by three times a '0'
    BLRF_u10 S0100 // Input was '0' followed by a '1' and two '0'
    BLRF_u10 S1100 // ...
    ...
    BLRF_u10 S1111

...

S0100:
    IN       r1, r0
    BRU      r1
    BLRF_u10 S01000000
    BLRF_u10 S01000001
    BLRF_u10 S01000010
    BLRF_u10 S01000011
    ...
    BLRF_u10 S01001111
\end{lstlisting}

Obviously, extra instructions need to be added to perform operations, and
the state space needs to be pruned to avoid unreachable states. For
example, one may always expect at least three equal bits in a row, eg
patterns such as ``00100'' are impossible. In this case many of the above
states are illegal and can be covered by a single ERROR state.

Note that the BRU instruction jumps over $n$ 16-bit instructions, and that all
entries in the jumptable should hence be short instructions. Hence they
have been specified as being \lstinline+BLRF_u10+ instructions.

\subsection{Encoding the state transitions in a hash table}

The above strategies work fine when small numbers of bits are input at a
time. When large numbers of bits are input that contain only few legal
sequences, these sequences can be stored in a hash table, and hash function
used to perform the state transitions. For example, if a low frequency
signal is sampled at a high rate, and the data is buffered into a 32-bit
value, the only legal values expected are:
\begin{lstlisting}
00000000000000000000000000000000
00000000000000000000000000000001
00000000000000000000000000000011
00000000000000000000000000000111
...
01111111111111111111111111111111
11111111111111111111111111111111
11111111111111111111111111111110
11111111111111111111111111111100
...
10000000000000000000000000000000
\end{lstlisting}
A hashtable can be built containing those values (see
Section~\ref{section:hash}), this hashtable can contain state values and
encode operations to be performed on state transitions.
\begin{lstlisting}
while(1) {
    p :> x;
    hash = hashValue(x);
    state = newState(state, hash)
    // Operations based on state.
}
\end{lstlisting}
Given that only 64 legal values need to be encoded, a polynomial with 6 or
7 bits will probably do the trick, and all polynomials of 6 and 7 bits can
be searched ones in order to create an optimal hash.

\subsection{Parsing an aligned bit stream by sampling}

If a bit stream has a known frequency relative to the XCore (give or take a
few percent), then the stream can be parsed by oversampling the data on a
port by a factor $n$, waiting for the start-bit, parse the $n/2$th bit, and
then every $n$th bit until the end of the packet.

For example, suppose that we expect a stream of bits at 12.288 Mhz, then we
can oversample at 100 Mhz (oversampled by a factor 8.13). Wait for the
start bit, and then sample bits 4, 12, 20, 28, 37, 45, 53, 61, etc.

In order to sample those bits, the port is set to buffer 32 bits, and on
the first word the bits are masked out using a mask \lstinline+0x08080808+.
In the second word, the mask used is \lstinline+0x04040404+, etc. Each mask
leaves four recovered bits in four places in the word, and these can be
recovered by applying a CRC with a polynomial of \lstinline+0xf+, which
implements a perfect hash onto the last four bits, and a lookup table with
16 elements to recover the 16 possible sampled values.

\begin{lstlisting}
p when pinsneq(0) :> int _;        // align first bit
p :> word;                         // read first word
fourBits = (word << 4) & 0x80808080;
crc32(fourBits, 0xf, 0xf);         // compress bits
data = lookupCrcF[fourBits];       // recover data
p :> word;                         // read second word
fourBits = (word << 5) & 0x80808080;
crc32(fourBits, 0xf, 0xf);
data = data << 4 | lookupCrcF[fourBits];
\end{lstlisting}%%%>> >> >>

Note that rather than using different masks, the same mask is reused on
each inputted word, and the input data is shifted. This means that the four
sampled bits are always in the same location (bits 7, 15, 23, and 31), and
the same lookup table can be used on both the first and the second word.
The array to lookup the CRC values should be initialised with the values
\lstinline${8,9,12,13,7,6,3,2,10,11,14,15,5,4,1,0}$; the array values
depend on the mask, the polynomial, and the initial value chosen.

Note that the above code requires around five instructions for each word;
leaving plenty of time for other operations, such as NRZ decoding, or
removing stuff bits.

\subsection{Finding the alignment of a bit stream}

If instead of re-aligning a bit stream, it is just important to establish
the alignment, then the {\em count leading zeroes} instruction comes in
useful. A combination of an input followed by a \lstinline$clz()$ will, in a total of two
thread cycles, return the bit number of the first '1' bit that was
received. If the first one is required, the input data should be
complemented, using \lstinline$clz(~x)$. The bit reverse instruction can be
used to count the number of trailing zeroes: \lstinline$clz(bitrev(x))$.

\section{Generating bit streams}

The simplest method to generate a bit stream is to use a port, and to
output successive values to that port. Eg:

\begin{lstlisting}
p <: 0;
p <: 1;
p <: 0;
p <: 1;
p <: 1;
\end{lstlisting}

This code will generate a sequence \lstinline$01011$ on port \lstinline$p$. If the
bits have to be outputted at a precise time, then the real time clock or a
clocked port can be used to achieve this.

An efficient method to output multiple synchronised output streams is to
make sure that all ports are clocked synchronously, by buffering ports, and
by ensuring that all buffers are always kept full. All these methods are
detailed in the XC programming manual~\cite{xc-en-ebook}.

Alternatively, ports can be clocked of one another. That is, one output
port is clocked of a divided reference clock, and this port is then used as
a clock for one or more other ports. As an example we show part of a 
JTAG implementation.

There are four ports, and two clocks in this example. The four ports drive the
TCK, TDI, and TMS signals, and sample the TDO signal. One of the clocks is
used to clock the TCK pin, the other clock is used to clock the TMS, TDI,
and TDO pins:

\begin{lstlisting}
buffered out port:32 jtag_pin_TCK  = XS1_PORT_1D;
buffered out port:32 jtag_pin_TDI  = XS1_PORT_1A;
buffered in port:32 jtag_pin_TDO  = XS1_PORT_1B;
buffered out port:4 jtag_pin_TMS  = XS1_PORT_1C;

clock tck_clk = XS1_CLKBLK_1;
clock jtag_clk = XS1_CLKBLK_2;
\end{lstlisting}

The initialisation function sets up the clock-blocks, ports, and clock
sources as follows:
\begin{lstlisting}
init() {
    configure_clock_rate(tck_clk, 100, 10);
    configure_out_port(jtag_pin_TCK, tck_clk, 0xffffffff);

    configure_clock_src(jtag_clk, jtag_pin_TCK);
    configure_out_port(jtag_pin_TDI, jtag_clk, 0);
    configure_in_port(jtag_pin_TDO, jtag_clk);
    configure_out_port(jtag_pin_TMS, jtag_clk, 0);
    start_clock(tck_clk);
    start_clock(jtag_clk);
}
\end{lstlisting}
\lstinline+tck_clk+ is set to tick at 10 Mhz, the TCK pin is set to be
clocked of that 10 Mhz clock and initialised to all ones (a high value),
the \lstinline+jtag_clk+ is set to be clocked of the TCK pin, and the other
three ports are clocked of the \lstinline+jtag_clk+, initialising the
output pins with 0. The clocks are then started.

After all the setup, data can now be input and output to the TDO, TDI, and
TMS pins. The trick is to always first place the data on the output port,
and then generate a train of clock pulses on TCK. Note that the program will
continue while the clock pulses are being generated, so there are places
where the program has to wait for all clock pulses being generated.

Initially, the protocol requires us to assert TMS for one clock tick, and
then keep it low for two clock ticks. That is achieved by the following
sequence:
\begin{lstlisting}
    jtag_pin_TMS <: 0b0001;
    jtag_pin_TCK:6 <: 0b101010;      // 3 Clock pulses
    sync(jtag_pin_TCK);
\end{lstlisting}
The data \lstinline$0001$ is placed int he TMS port, and because
\lstinline+jtag_pin_TCK+ is initially high, one TMS bit will be clocked out
on every zero bit of TCK. Three bits will be clocked out in total. The call to
\lstinline$sync$ causes the program to pause until all 6 bits have been
shifted out on TCK, and three bits to have been shifted out of TMS as a result.

Second, the protocol requires us to place data on TDI, clock this data out,
and input data on TDO:
\begin{lstlisting}
    jtag_pin_TDI <: in0;
    clearbuf(jtag_pin_TDO);
    jtag_pin_TCK <: 0xAAAAAAAA;  // 16 Clock pulses
    jtag_pin_TCK <: 0xAAAAAAAA;  // 16 Clock pulses
    jtag_pin_TDO :> out1;
\end{lstlisting}
The first line places 32 bits of data from the variable \lstinline$in0$
into the TDI port; preparing it for transmission. The second line empties
the input buffers of the TDO port, throwing away any data that was clocked
in previously. The third and fourth line generate a total of 32 clock
pulses on the TCK, clocking out all data on TDI, and clocking in 32 bits on
TDO. The last line inputs the data from TDO into the variable
\lstinline$out0$. This statement will block until all 32 bits are present,
and will hence wait for all clocks to be generated.

Using this method also gives flexibility to, for example, generate clocks
that are non symmetrical.

\section{Pseudo Random Numbers}

A separate app-note describes how to generate random numbers using the CRC
instruction, and how to generate real random numbers~\cite{random}. In short, a
pseudo random sequence can be generated using the CRC instruction and a
suitable polynomial.

For specific purposes, random numbers may need to have a specific
distribution. As an example, we show here how to make a pseudo random
number generator that generates random values with a Triangular
Probability Density Function (TPDF), used in, for example, audio dithering. 

Below is the code to generate those numbers. It generates a 32-bit pseudo random
number, takes the bottom and top bits, sums those, and normalises it around
0. It generates random numbers in the range $[1..2^{2B}-1]$, with a
PDF $P(x) = 2^{-B}-2^{-2B}|x-2^{B}+1|$:
\begin{lstlisting}
#define POLYNOMIAL 0xEDB88320
#define B 8

unsigned int seed = 0xffffffff;

int tpdf() {
  int value1, value2;

  crc32(seed, ~0, POLYNOMIAL);
  value1 = seed >> (32-B);
  value2 = seed & ((1<<B)-1);
  return value1 + value2 + 1;
}
\end{lstlisting}
This value can, for example, be used to initialise the accumulator prior to
performing a series of multiply accumulate operations.
\newpage
\section{Computing a logarithm or sqrt}

The XS1 has an instruction to count the number of leading zeroes of a bit
pattern, \lstinline+clz()+. This function can be used to efficiently
estimate the logarithm of a number. Assuming $x \not = 0$, then:
\[
\lfloor \log_2 x \rfloor = bpw - 1 - clz(x)
\]
This logarithm can be used as a first estimate for a square root, since:
\[
\sqrt{x} = x^{\frac{1}{2}} = 2^{\frac{\log_2 x}{2}}
\]
This is all implemented using shift operations:
\begin{lstlisting}
sqrtx = 1 << ((31-clz(x))>>1);
\end{lstlisting}
This estimate can be improved iteratively using the Newton-Raphson algorithm. Since the
first bit is of the square root is already correct, only 3 or 4 iterations
will produce an accurate square root:
\begin{lstlisting}
int sqrt(int x) {
  int d, root = 1 << ((31-clz(x))>>1);
  do {
    d = (root*root - x)/(2*root);
    root = root - d;
  } while (d > 1 || d < -1);
  return root;
}
\end{lstlisting}
See Hacker's delight~\cite{warrenjr} and Paul Hsieh's
website~\cite{sqrt-hsieh} for an in-depth discussion.

\section{Clearing two registers simultaneously}

Two registers can be cleared simultaneously by executing an \lstinline+LSUB+
instruction. 
\begin{lstlisting}
    LSUB d, e, d, d, c
\end{lstlisting}
will clear $d$ and $e$ in a single clock cycle, provided the bottom bit of
$c$ is zero. It will provide all ones in both $d$ and $e$ if $c$ is one. If
any register $c$ is known to contain a word address, the instruction
\begin{lstlisting}
    LSUB d, e, c, c, c
\end{lstlisting}
will clear both $s$ and $e$.

Similarly, LADD can be used to copy oen register and clear another register
simultaneously. 


\section{Using extra registers}

The XCore has 12 general purpose registers. If this is not sufficient, then
it may be possible to use the $cp$, $dp$, and $sp$ registers to store a
memory address. Although they cannot be used in all instructions, they can
be used to efficiently store and retrieve values from memory.

For example, $dp$ can be set to point to the base of an array, and the
$LDWDP$ and $STWDP$ instructions can be used to access values in that
array. Note that the index has to be constant. $cp$ can be used too, and
has the added advantage of allowing a wide range to be indexed with a short
instruction. However, there is no instruction to store data relative to
$cp$ (as it is meant to point to the constant pool).

The $dp$, and $sp$ pointers can be advanced using the $EXTSP$ instruction.
Note that each thread has its own $dp$, $cp$, and $sp$ register, so a
thread can safely reappropriate any of those.

\section{Building short FIFOs}

A channel can be used as a short fifo, to synchronise two, otherwise
asynchronous, processes. To use it as a short fifo, output
single bytes or words to the channel end using the \lstinline+outuchar()+,
\lstinline+outuint()+, \lstinline+inuchar()+, and \lstinline+inuint()+
primitives.

The \lstinline+uchar+ primitives send 8-bit data values through the channel.
The input primitive will block until data is available, and the output
primitive will block until space is available. A channel
can hold at least 8 bytes; there is no guaranteed upperlimit on the number
of bytes it can store.

The \lstinline+uint+ primitives send words through the channel.
The input primitive will block until data is available, and the output
primitive will block until space is available. A channel
can hold at least 64 bits (32-bit words) ; there is no guaranteed upperlimit on the number
of words it can store.

A usage model is where two threads should stay loosely coupled, in
that \lstinline+B()+ should be no further than two iterations ahead of
\lstinline+A()+:

\begin{lstlisting}
A(chanend x) {             B(chanend x) {
  unsigned char i = 0 ;      unsigned char i = 0;
  outuchar(x, i++);          while(1) {
  outuchar(x, i++);            inuchar(x);
  while (1) {                  // ... do work
    inuchar(x);                outuchar(x, i);
    // ... do work           }
    outuchar(x, i++);      }
  }
}
\end{lstlisting}

Initially, \lstinline$A$ puts two tokens in the FIFO to \lstinline$B$. This
indicates that \lstinline$B$ can complete two rounds of work without having
to synchronise. Every time that \lstinline$B$ completes an iteration, it
puts a token in the FIFO to \lstinline$A$ indicating that it has completed
it, \lstinline$A$ will not start its work until \lstinline$B$ has
completed, and will signal its iteration.

When a FIFO is empty, it indicates that the thread on the receiving side of
that thread cannot progress. When a FIFO contains tokens, it means that the
thread at the receiving end can continue. The FIFOs never contain more than
two tokens.

\section{Division and modulo}

The division instruction on the XS1 shares a divider between all threads,
and takes a number of thread cycles (32) to complete. Division is hence
slower than any other arithmetic instruction; and when multiple threads
perform divisions at the same time, they will slow each other down; a
division may take 32 thread cycles to complete if a thread is unlucky.

Sometimes divisions can be avoided; using well known methods:
\begin{itemize}
  \item {\em Use a shift operation}. A right shift of $n$ bits is
    equivalent to unsigned division by $2^n$. For negative numbers, one has
    to be careful that a right shift rounds towards minus infinity.
  \item {\em Multiply by the inverse}. Sometimes the inverse is easily
    calculated, for example when dividing by a constant. In this case, one
    can, at compile time, compute the inverse ($1/n$) and then at run time
    multiply by this number. For an integer division, the inverse is always
    less than one, hence the number to store is $2^{32}/n$ which is then
    multiplied using one of the long multiply instructions (LMUL, MACCS). 
    This will compute the result of the division in the most significant 32
    bits, although rounding may not be precise.
\end{itemize}
See Hacker's delight~\cite{warrenjr} for a detailed discussion on this subject

\section{Using multiple threads for super linear speedup}

In programs there are often two functions calling each other where the
calling function is producing data, and the called function is storing the data. 
By using two threads you can more than double the speed of the
code. This is due to each thread having access to a set of registers to
hold data, and because two threads eliminate the overhead caused by function calls.

\subsection{Code structure}

As an example, we use JPEG encoding where discretised DCT parameters are
stored as a string of bits, and runs of '0' values are run length encoded.
The two functions are doing the encoding and the bit shuffling/storing. The
code is based on source code from \lstinline$libjpeg$ by Thomas G Lane et al.

The program comprises two functions, \lstinline+encode+ and
\lstinline+emit_bits+, \lstinline+encode+ makes repeated calls to
\lstinline+emit_bits+. The trick is that the latter function requires some
persistent state. This state can be stored in one of three places:
\begin{itemize}
  \item It can be stored in a structure that is passed to
    \lstinline+emit_bits+ on every call (an object oriented way of programming)
  \item It can be stored in a structure that is a persistent variable inside
    \lstinline+emit_bits+  (traditional procedural programming style)
  \item It can be stored in a thread that runs \lstinline+emit_bits+
    (a concurrent programming style)
\end{itemize}
The three programs are shown in an appendix on pages \pageref{r1}, \pageref{r2}, and
\pageref{r3}. Global definitions used by all three programs is shown on
\pageref{r4}.

\subsection{Timings}

The execution times are as follows (measured on a 400 Mhz XCore, compiled
with -O2 and array bound checks switched off):
\begin{center}
\begin{tabular}{llr}
  Verison & Programming style & Time in $\mu$s \\
  \lstinline+encode_oo+ & Object Oriented style & 51.21 \\
  \lstinline+encode_p+ & Procedural style & 51.12 \\
  \lstinline+encode_c+ & Concurrent style & 16.08 \\
\end{tabular}
\end{center}

Note that the concurrent version runs more than three times faster, using only
two threads. The extra factor 1.5 speed-up is due to two factors:
\begin{enumerate}
\item Foremost, the program has access to twice the number of register
  variables. This means that all variables are kept in registers. In
  particular, the state used by \lstinline+emit_bits+ is kept in registers.
\item 
  Second, Function calls are avoided, avoiding the need to save registers, and
  create parameter lists. This can be resolved by inlining functions, but
  in addition to a code bloat (\lstinline+emit_bits+ is called three
  times), it also leads to registers being spilled to the stack.
\end{enumerate}


\subsection{Code listings for threads}

All three code segments assume the following global definitions:

\begin{lstlisting}
struct pers {
    int current;
    int length;
    int ncodes;
    int codes[512];
};

int ehufco[256], ehufsi[256];
\end{lstlisting}
\label{r4}

The program written in an object-oriented, procedural, and concurrent style are listed
on the subsequent three pages. The last page shows the main program.

\newpage
\begin{lstlisting}
void emit_bits_oo(struct pers &state,int code,int length) {




    state.length += length;
    if (state.length > 32) {
        int t;
        state.length -= 32;
        t = state.current << (length - state.length);
        t |= code >> state.length;
        state.codes[state.ncodes] = t;
        state.ncodes++;
        state.current = code;
    } else {
        state.current <<= length;
        state.current |= code;
    }

}
void encode_oo(int block[64]) {
    int temp, i, k, temp2, nbits;
    int r = 0;
    struct pers state; state.ncodes = state.length = 0;
    for (k = 0; k < 64; k++) {
        if ((temp = block[k]) == 0) {
            r++;
        } else {
            while (r > 15) {
                emit_bits_oo(state,ehufco[0xF0],ehufsi[0xF0]);
                r -= 16;
            }
            temp2 = temp;
            if (temp < 0) {
                temp = -temp;
                temp2--;
            }
            nbits = 32-clz(temp);
            i = (r << 4) + nbits;
            emit_bits_oo(state, ehufco[i], ehufsi[i]);
            emit_bits_oo(state, (unsigned int) temp2, nbits);
            r = 0;
        }
    }
}
\end{lstlisting}
\label{r1}
\newpage
\begin{lstlisting}
void emit_bits_p(int code, int length) {
    static struct pers state;



    state.length += length;
    if (state.length > 32) {
        int t;
        state.length -= 32;
        t = state.current << (length - state.length);
        t |= code >> state.length;
        state.codes[state.ncodes] = t;
        state.ncodes++;
        state.current = code;
    } else {
        state.current <<= length;
        state.current |= code;
    }

}
void encode_p(int block[64]) {
    int temp, i, k, temp2, nbits;
    int r = 0;

    for (k = 0; k < 64; k++) {
        if ((temp = block[k]) == 0) {
            r++;
        } else {
            while (r > 15) {
                emit_bits_p(ehufco[0xF0], ehufsi[0xF0]);
                r -= 16;
            }
            temp2 = temp;
            if (temp < 0) {
                temp = -temp;
                temp2--;
            }
            nbits = 32-clz(temp);
            i = (r << 4) + nbits;
            emit_bits_p(ehufco[i], ehufsi[i]);
            emit_bits_p((unsigned int) temp2, nbits);
            r = 0;
        }
    }
}
\end{lstlisting}
\label{r2}

\newpage
\begin{lstlisting}
void emit_bits_c(streaming chanend inp) {
  int code, length, state_current;
  int state_length = 0, state_ncodes = 0, state_codes[512];
  while(1) {
    inp :> code;   inp :> length;
    state_length += length;
    if (state_length > 32) {
        int t;
        state_length -= 32;
        t = state_current << (length - state_length);
        t |= code >> state_length;
        state_codes[state_ncodes] = t;
        state_ncodes++;
        state_current = code;
    } else {
        state_current <<= length;
        state_current |= code;
    }
  }
}
void encode_c(streaming chanend outp, int block[64]) {
    int temp, i, k, temp2, nbits;
    int r = 0;

    for (k = 0; k < 64; k++) {
        if ((temp = block[k]) == 0) {
            r++;
        } else {
            while (r > 15) {
                outp <: ehufco[0xF0]; outp <: ehufsi[0xF0];
                r -= 16;
            }
            temp2 = temp;
            if (temp < 0) {
                temp = -temp;
                temp2--;
            }
            nbits = 32-clz(temp);
            i = (r << 4) + nbits;
            outp <: ehufco[i]; outp <: ehufsi[i];
            outp <: (unsigned int) temp2; outp <: nbits;
            r = 0;
        }
    }
}
\end{lstlisting}
\label{r3}




\xmosbib

\section*{Release History}

\begin{small}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{| p{20mm} | p{12mm} | p{88mm}|}
\hline
\textbf{Date} & \textbf{Release} & \textbf{Comment} \\
\hline
20XX-XX-XX & 1.0 & First release \\
\hline
\end{tabular}
\end{small}


%\end{document}
\finish
